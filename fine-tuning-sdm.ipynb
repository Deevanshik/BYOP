{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10145029,"sourceType":"datasetVersion","datasetId":6262082}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import the dataset: `resized coco demo` from kaggle into the kaggle input directory. You can search `resized coco demo` in the datasets and you will find it.","metadata":{}},{"cell_type":"code","source":"import subprocess\nimport time\nimport os \nfrom tqdm.auto import tqdm\nimport PIL","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cloning the github repo of EveryDream v2\n!git clone https://github.com/victorchall/EveryDream2trainer.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/\n!mkdir -p /kaggle/working/drive/MyDrive/everydreamlogs/ckpt\n%cd /kaggle/working/EveryDream2trainer\n!python utils/get_yamls.py\n%cd /kaggle/working/\n!mkdir input\n%cd /kaggle/working/EveryDream2trainer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MODEL_LOCATION = \"https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4-full-ema.ckpt\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Downloading the model from hugging face hub\nIf_Ckpt = False\nimport os\n\ndownload_path = \"\"\nsave_name = \"\"\n\nif \".co\" in MODEL_LOCATION or \"https\" in MODEL_LOCATION or \"www\" in MODEL_LOCATION:\n    MODEL_URL = MODEL_LOCATION\n    print(\"Downloading...\")\n    !wget $MODEL_LOCATION\n    print(\"Download completed!\")\n    download_path = os.path.join(os.getcwd(), os.path.basename(MODEL_URL))\nelse:\n    save_name = MODEL_LOCATION\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Upgrade the libraries to compatible versions\n!pip install --upgrade huggingface_hub diffusers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert the model to diffusers model\nsave_name = \"\"\nif download_path.endswith(\".ckpt\") or MODEL_LOCATION.endswith(\".ckpt\"):\n    MODEL_LOCATION = \"/kaggle/working/EveryDream2trainer/sd-v1-4-full-ema.ckpt\"\n    If_Ckpt = True\n    save_path = download_path\n    img_size = 512\n    upscale_attention = False\n    prediction_type = \"epsilon\"\n    inference_yaml = \"v1-inference.yaml\"\n    if If_Ckpt:\n        save_name = os.path.join(\"/kaggle/working/drive/MyDrive/everydreamlogs/ckpt/\", save_name)\n        print(save_name)\n    !python utils/convert_original_stable_diffusion_to_diffusers.py --scheduler_type ddim \\\n    --original_config_file $inference_yaml \\\n    --image_size $img_size \\\n    --checkpoint_path $MODEL_LOCATION \\\n    --prediction_type $prediction_type \\\n    --upcast_attention \\\n    --dump_path $save_name","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd /kaggle/working/EveryDream2trainer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Save_optimizer_state = False\nDisconnect_after_training =  True\nresume = False\nLearning_Rate = 1e-6\nMatch_text_to_Unet = False\nText_lr =  5e-7\nSchedule = \"constant\"\nText_lr_scheduler = \"constant\"\nlr_warmup_steps = 0\nlr_decay_steps = 0\nText_lr_warmup_steps = 0\nText_lr_decay_steps = 0\nif Match_text_to_Unet:\n  Text_lr = Learning_Rate\n  Text_lr_scheduler = Schedule\n  Text_lr_warmup_steps = lr_warmup_steps\n\nimport json\nfile_path = \"/kaggle/working/EveryDream2trainer/optimizer.json\"\nwith open(file_path, 'r') as file:\n    data = json.load(file)\n\ndata['base']['lr'] = Learning_Rate\ndata['text_encoder_overrides']['lr'] = Text_lr \ndata['base']['lr_scheduler'] = Schedule\ndata['text_encoder_overrides']['lr_scheduler'] = Text_lr_scheduler\ndata['base']['lr_warmup_steps'] = lr_warmup_steps\ndata['base']['lr_decay_steps'] = lr_decay_steps\ndata['text_encoder_overrides']['lr_warmup_steps'] = Text_lr_warmup_steps\ndata['text_encoder_overrides']['lr_decay_steps'] = Text_lr_decay_steps\n\n# Save the updated JSON data back to the file\nwith open(file_path, 'w') as file:\n    json.dump(data, file, indent=4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Gradient = \"--gradient_checkpointing \"\ntextencode = \"--disable_textenc_training\"\nshuffle = \"--shuffle_tags \"\nDrive = \"\"\nDX = \"\"\nvalidate = \"\"\nwandb_settings = \"\"\nmodel = \"/kaggle/working/drive/MyDrive/everydreamlogs/ckpt\"\nClip_skip = \"1\"\nBatch_Size = \"4\"\nGradient_steps = \"1\"\nConditional_DropOut = \"0.04\"\ndataset = \"/kaggle/input/resized-coco-demo/Resized COCO demo/\"\nPicture_flip = \"0\"\nMax_Epochs = \"6\"\nProject_Name = \"MyProject\"\nResolution = \"512\"\nSample_File = \"path_to_sample_file\"\nSteps_between_samples = \"10\"\nSave_every_N_epoch = \"6\"\nTraining_Seed = \"42\"\nzero_frequency_noise = \"0.01\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"command = [\n    \"python\", \"train.py\",\n    \"--resume_ckpt\", model,\n    Gradient.strip(),\n    textencode,\n    shuffle.strip(),\n    Drive,\n    DX.strip(),\n    \"--clip_skip\", Clip_skip,\n    \"--batch_size\", Batch_Size,\n    \"--grad_accum\", Gradient_steps,\n    \"--cond_dropout\", Conditional_DropOut,\n    \"--data_root\", dataset,\n    \"--flip_p\", Picture_flip,\n    \"--log_step\", \"25\",\n    \"--max_epochs\", Max_Epochs,\n    \"--project_name\", Project_Name,\n    \"--resolution\", Resolution,\n    \"--sample_prompts\", Sample_File,\n    \"--sample_steps\", Steps_between_samples,\n    \"--save_every_n_epochs\", Save_every_N_epoch,\n    \"--seed\", Training_Seed,\n    \"--zero_frequency_noise_ratio\", zero_frequency_noise,\n]\ncommand = [arg for arg in command if arg.strip()]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install compel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\nsubprocess.run(command)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}